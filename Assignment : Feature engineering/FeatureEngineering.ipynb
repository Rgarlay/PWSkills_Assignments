{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVluWhrG+0ESBbsuJquFs8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rgarlay/PWSkills_Assignments/blob/main/Assignment%20%3A%20Feature%20engineering/FeatureEngineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment Questions"
      ],
      "metadata": {
        "id": "8Qt_hHA_Kmvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1Q. What is a parameter.\n",
        "Ans:- During the definition of a function, the argument passed are called parameters.\n",
        "For example, consider the following function:\n"
      ],
      "metadata": {
        "id": "JEdqCMOXB_wj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByJIzaMsKiXk",
        "outputId": "d0ddd7b6-cd8c-4b52-9ecc-304cbde03454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ravi, nice to meet you!\n"
          ]
        }
      ],
      "source": [
        "#1st question\n",
        "def greet(name):    ##Name is the parameter here.\n",
        "  print(f'{name}, nice to meet you!')\n",
        "greet('Ravi')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "While a function necessarily have parameters, When we call a function with parameters, we have give arguments to these parameters."
      ],
      "metadata": {
        "id": "EbtboLZPCEMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2Q.What is correlation?\n",
        "Ans:- Correlation is a statistical concept that describe how 2 seemingly independent quantities are related with each other.\n",
        "It ranges from -1 to +1\n",
        "-1=> Negative linear correlation.\n",
        "0 => variables are completely independent of each other.\n",
        "+1 => positive linear correlation.\n",
        "\n",
        "`Pearson corr(x,y) = covariance(x,y)/((std dev. x )*(std dev. y)`\n",
        "\n",
        "Suppose 'y' has negative correlation with 'x'.\n",
        "It means that, as x increases, y will decrease.\n",
        "The relation may be linear(Pearson correlation) or non-linear(Spearson corr.)."
      ],
      "metadata": {
        "id": "8IMia-cjCGiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3Q.Define Machine Learning. What are the main components in Machine Learning?\n",
        "Ans:- Machine learning is a field of study, which includes development of statistical algorithms that can learn from data and perform tasks without explicit instructions.\n",
        "\n",
        "There are 4 components of machine learning:\n",
        "1. Supervised Learning:- We have data organized and sorted into columns with labels. Machine trains on this, to find pattern among the data. This requires human intervention.\n",
        "2. Unsupervised Learning:- Our data is not labelled and not sorted. We use this to find pattern hidden among the data. It doesn't require human intervention.\n",
        "3. Reinforcement Learning:- This includes giving feedback on each to reinforce the preferred behavior from machine. It includes awarding the desired behavior and punishing the undersired behavior.\n",
        "4. Semi supervised Learning:- This requires a combination of both supervised and unsupervised learning. The algorithms use labelled and unlabeled data to build the model.\n"
      ],
      "metadata": {
        "id": "9nY1yzqoCOKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4Q.How does loss value help in determining whether the model is good or not?\n",
        "Ans:- During ML model development, we evaluate the model with loss function.\n",
        "This helps optimize and parametrize the model.\n",
        "\n",
        "For example, for regression with RMSE, if we have high value of loss. This interprets as having huge difference between actual datapoints and datapoints predicted by algorithms.\n",
        "Hence, performance of model is quantified and monitored. In such a case, optimizing the model to minimize the loss becomes 'goodness of ML model' measure.\n"
      ],
      "metadata": {
        "id": "460x66GRCNCd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5Q:-What are continuous and categorical variables?\n",
        "Ans: - Categorical Variable: - Variables that take distinct/discrete values are called\n",
        "categorical variables. For example Gender, color or cities, ratings measure. They can take numerical or char datatypes.\n",
        "\n",
        "Continuous Variable:- Variables that can take any value from the spectrum of numbers is called continuous variable.\n",
        "For example, length, mass, speed etc.\n",
        "They are numerical datatypes."
      ],
      "metadata": {
        "id": "ArTXNtsfCfFu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6Q:- How do we handle categorical variables in Machine Learning? What are the common  techniques?"
      ],
      "metadata": {
        "id": "jkVD2x_5CiMr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans:- Since Most ML algorithms take numerical data in its input, we need to preprocess categorical (specially labelled) data.\n",
        "To handle categorical variables, we can encode them.\n",
        "\n",
        "OHE:- OneHotEncoding is an effective method to encode variables whose range is nominal data. This creates a separate row for each value (say 'a'), where the value is 1 when it is 'a' and 0 otherwise.\n",
        "\n",
        "LabelEncoding:- Label Encoding is used primarily used to encode target data. For example academic result (pass/fail). This encodes the label/categories, allowing us to rank it and preserving the order.\n",
        "\n",
        "OrdinalEncoding: - OrdinalEncoding is used to transform categorical data that has ordinal relation among its categories. It preserves the order and allow us to turn our features into numerical categories, which are compatible with ml algorithms.\n",
        "For example, academic qualification ranking can be custom encoded using this."
      ],
      "metadata": {
        "id": "xT2Fw7chCkpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6 question\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder()\n",
        "color = np.array([['red','blue','pink']])\n",
        "print(color)\n",
        "color_1 = ohe.fit_transform(color)\n",
        "print(color_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTPa3bRGMXjt",
        "outputId": "75a48791-3ad5-439d-a255-acaec8c7b55f"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['red' 'blue' 'pink']]\n",
            "  (0, 0)\t1.0\n",
            "  (0, 1)\t1.0\n",
            "  (0, 2)\t1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "acad_qual = ['pass','fail']\n",
        "encode = LabelEncoder()\n",
        "acad = encode.fit_transform(acad_qual)\n",
        "acad_qual = np.array(acad_qual)\n",
        "dict_1 = {i:j for i,j in zip(acad_qual,acad)}\n",
        "dict_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCg8WihDVKkY",
        "outputId": "b095b20f-71f6-43ee-831c-9b10ea3d83a1"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pass': 1, 'fail': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "custom_order = [['HS','SS','UG','PG','PhD']]\n",
        "\n",
        "acad_qual = np.array([['HS'], ['SS'], ['UG'], ['PG'], ['PhD']])\n",
        "\n",
        "encode = OrdinalEncoder(categories = custom_order)\n",
        "\n",
        "acad = encode.fit_transform(acad_qual)\n",
        "\n",
        "acad = acad.flatten()\n",
        "\n",
        "acad_qual = acad_qual.flatten()\n",
        "\n",
        "dict_1 = {i:j for i,j in zip(acad_qual,acad)}\n",
        "\n",
        "dict_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZK07nTgb54P",
        "outputId": "92be8c0f-aec1-4941-a20b-278b6e7a8260"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'HS': 0.0, 'SS': 1.0, 'UG': 2.0, 'PG': 3.0, 'PhD': 4.0}"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7Q:- What do you mean by training and testing a dataset?\n",
        "\n",
        "Ans:- Whenever we are developing an ML model, we have to supply it some data.\n",
        "This allows the ml algorithm to familiarize with data and understand the patterns.\n",
        "The dataset that contains all of data for such purpose is called training data.\n",
        "\n",
        "After training, we have to make sure that our model also works sufficiently good on unseen data. Hence we subject our model to data that it has not seen before.\n",
        "The dataset that is used for this purpose is called testing dataset."
      ],
      "metadata": {
        "id": "q3W6GFVPCxvS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###8Q:- What is sklearn.preprocessing?\n",
        "Ans:- Sci-kit learn (or sklearn) is a library.\n",
        "sklearn.preprocessing is a module of this library.\n",
        "It has all of the functions that we needs to preprocess and turn the data into vector representations.\n",
        "For example, LabelEncoder, OneHotEncoder, OridnalEncoder, Imputer, StandardScaler etc.\n"
      ],
      "metadata": {
        "id": "AVYemQ3JC_wW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###9Q:- What is a Test set?\n",
        "Ans:- The dataset that we use to test our trained model, how it performs on unseen data, is called test set.\n"
      ],
      "metadata": {
        "id": "z_HVn3ZHDECp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###10Q: - How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?\n",
        "Ans:- Given a dataset, we can use sci-kit learn library to split our data into training and testing parts.\n",
        "Further is a example dataset, divided into training and testing using model_selection module and train_test_split function.\n",
        "\n",
        "To approach a ML problem.\n",
        "We need to: -\n",
        "1. Understand the problem\n",
        "2. Collection and sorting of data\n",
        "3. Descriptive analytics\n",
        "4. Missing Value and Outlier handling\n",
        "5. Feature transformation and Engineering\n",
        "6. Selecting suitable algorithm\n",
        "7. Fine tune parameters"
      ],
      "metadata": {
        "id": "qFwwU4xuDHJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#10 question\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "print(iris_df.shape)\n",
        "from sklearn.model_selection import train_test_split\n",
        "x,y = train_test_split(iris_df, test_size = 0.3,random_state = 42)\n",
        "print(f'train_size = {x.shape}, and test size = {y.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIaKTCBghCWp",
        "outputId": "e64326dd-e3c7-4f2b-8f7d-f657415c4dd0"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 4)\n",
            "train_size = (105, 4), and test size is (45, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###11Q:- Why do we have to perform EDA before fitting a model to the data?\n",
        "Ans:-  Raw gathered data has inconsistencies in terms of data quality.\n",
        "We can encounter missing information(values) and outliers or incompatible datatypes.\n",
        "We need to perform certain statistical and analytical operations on data\n",
        "to clean it and make it suitable for training.\n",
        "Hence, EDA is essential."
      ],
      "metadata": {
        "id": "VVSuWpk7DNAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###12Q:-What is correlation?\n",
        "Ans:- A statistical quantity that describe the relation between 2 seemingly unknown parameters.\n",
        "It ranges from -1 to +1.\n",
        "\n",
        "-1=> Negative relation.\n",
        "\n",
        "0 => variables are completely independent of each other.\n",
        "\n",
        "+1 => positive relation.\n",
        "High value on either side describe strong mutual dependence."
      ],
      "metadata": {
        "id": "SdSr5wMLDT_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###13Q:- What does negative correlation mean?\n",
        "Ans:- Negative correlation mean that as our one quantity(say 'x') increases, 'y' decreases.\n",
        "Depending on the correlation metric that we use, this may be linear or non linear.\n",
        "For example, the older the car gets, lower will be its resale value.  We will quantify such case with negative correlation.\n"
      ],
      "metadata": {
        "id": "QRR12yayDZul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###14Q:-How can you find correlation between variables in Python?\n",
        "Ans:- 1. We can directly use the formula.\n",
        "\n",
        "`Pearson corr(x,y) = covariance(x,y)/((std dev. x )*(std dev. y)`\n",
        "\n",
        "2. If our data can be sorted into a dataset, then we can use pandas for such task.\n",
        "\n",
        "For example, in the iris dataset, to calculate correlation using pandas, we can do as follows.\n"
      ],
      "metadata": {
        "id": "PZZIC0VIDdJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#14 question\n",
        "iris_df['sepal length (cm)'].corr(iris_df['sepal width (cm)'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3jXuyEUczaf",
        "outputId": "3f1ade64-2307-44fa-cf6a-307645532a9a"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.11756978413300208"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###15Q:-What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "Ans:- When a variable influences other to behave a certain way, then we call it causation.\n",
        "For example, a plant grows faster when fertilizer is added to it. We can assert that if we add fertilizer to a plant, it will definitely boost its growth.\n",
        "\n",
        "Correlation is when 2 quantities move in a related manner. They need not necessarily have an impact on one another, but their value move in a entangled manner.\n",
        "The more you drink coffee, the more hours you will stay awake.\n",
        "\n",
        "However both correlation and causation are different. 2 variables can be correlated but not cause each other.\n",
        "For example, most heart attack cases happen between December and January. Also, the cauliflower, carrots vegetables are most commonly consumed. But it does not mean that these vegetables cause heart attack. They happen to move in a related manner throughout seasons.\n",
        "They are correlated, but one does not cause the other.\n"
      ],
      "metadata": {
        "id": "izrPIN7zDivn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###16Q:- What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "Ans:- An optimizer is an algorithm or method that is used to minimize the error during the Machine learning process.\n",
        "In linear regression, optimization algorithm is used to help function weight converge.\n",
        "Some example of gradient descent are:\n",
        "Gradient descent, batch gradient descent, mini batch gradient descent, stochastic gradient descent.\n"
      ],
      "metadata": {
        "id": "LL-b977lDp8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###17Q:- What is sklearn.linear_model?\n",
        "Ans:- It is a sklearn.linear_model is a sci-kit learn module that has linear models inside it.\n",
        "We can import regression/logistic regression/ridge/lasso or elasti-net regression inside it.\n",
        "Further, this allows us to build regression/classification models inside it.\n"
      ],
      "metadata": {
        "id": "rs4YOk7EDs1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###18Q:- What does `model.fit()` do? What arguments must be given?\n",
        "Ans:- `model.fit()` applies algorithm to the data and builds the model.\n",
        "We pass training data as argument( training_features(x) and training_target(y))."
      ],
      "metadata": {
        "id": "FnzKX0n3Dv-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###19Q:- What does model.predict() do? What arguments must be given?\n",
        "Ans:- model.predict() applies already built model to the test_features and predicts the test_targets. This may be regression or classification numpy array.\n"
      ],
      "metadata": {
        "id": "RLhsTFSBD2P-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###20Q:- Question same as 5th"
      ],
      "metadata": {
        "id": "O5GMDGYCD87A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###21Q:- What is feature scaling? How does it help in Machine Learning?\n",
        "Ans:- Consider example of loan approval with 2 training features (income,age) and target column as Boolean value(1/0).\n",
        "Now, income is in thousands and age for working individual is above 18 to 60.\n",
        "But notice that due to difference in order of magnitude, the algorithm can neglect one in comparison to other.\n",
        "To solve problems like above, we scale our feature to be of same range.\n",
        "We can use standardscaling/normalization for it.\n",
        "\n",
        "This helps in machine learning, as it allows algorithm to learn meaningful patterns from different features regardless of their initial order of magnitude.\n"
      ],
      "metadata": {
        "id": "WWTUblnkD59r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###22Q:- How do we perform scaling in Python?\n",
        "Ans:- To perform feature scaling, we have 2 primary methods:\n",
        "1. standardization:- This transforms the mean to be 0 and standard deviation to be 1.\n",
        "2. Normalization:- Normalizing data makes our range of data to be between 0 and 1.\n",
        "\n",
        "How to transform:\n",
        "\n"
      ],
      "metadata": {
        "id": "LC-s8qmZEC8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#21 Question\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "min_max = MinMaxScaler()\n",
        "scaler = StandardScaler()"
      ],
      "metadata": {
        "id": "tHIbAXNKeXub"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = min_max.fit_transform(iris_df[['sepal length (cm)']])\n",
        "print(f'max of x is {max(x)}, minimum of x is{min(x)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRRXNvLTfedP",
        "outputId": "de38f611-4d56-4a28-9268-579ac49a40ee"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max of x is [1.], minimum of x is[0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = scaler.fit_transform(iris_df[['sepal width (cm)']])\n",
        "print(f'max of x is {max(y)}, minimum of x is{min(y)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUyYsrV5AqqS",
        "outputId": "0663f870-b51a-45ec-f6e0-78b75171aa3a"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max of x is [3.09077525], minimum of x is[-2.43394714]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###25:- Explain data encoding.\n",
        "Ans:- Encoding is the process of converting categorical data into which can be used for machine learning. For example:\n",
        "\n",
        "\n",
        "This is necessary because very few algorithms can process text categorical data directly.\n",
        "\n"
      ],
      "metadata": {
        "id": "JnLnvWbqEI3Y"
      }
    }
  ]
}