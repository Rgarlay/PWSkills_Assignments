{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHC6R8ak7UU/tSlsScM7Gr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rgarlay/PWSkills_Assignments/blob/main/Assignment%3A%20Logistic%20Regression/Logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.What is Logistic Regression, and how does it differ from Linear Regression.\n"
      ],
      "metadata": {
        "id": "Fg3y2Jubfxvt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression is a classification ML algorithm.\n",
        "It is used for building decision boundaries, seperating different classes.\n",
        "\n",
        "Conceptually, It differes from Linear Regression in terms of its application.\n",
        "It is used to predict the class/probability of data point belonging to certain class whereas Linear Regression is used to predict new data points in the pre-learnt data patterns."
      ],
      "metadata": {
        "id": "07vhusSDf1AK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvkGEaxZfuav"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.What is the mathematical equation of Logistic Regression."
      ],
      "metadata": {
        "id": "QCdyrlffgxRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sigmoid function is mathematical fun. for Logistic Regression.\n",
        "\n",
        "```\n",
        "sigma(z) = 1/(1+exp(-z))\n",
        "```\n",
        "where\n",
        "\n",
        "`z = mx + c`\n"
      ],
      "metadata": {
        "id": "gz0civQzgzWx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d39pCsiFgy6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Why do we use the Sigmoid function in Logistic Regression."
      ],
      "metadata": {
        "id": "ICygWvjyhOf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sigmoid function is used for Logistic Regression because:\n",
        "\n",
        "1. Its range of variation is from 0 to 1.\n",
        "2. It is differentiable and optimizable (using gradient descent).\n",
        "3. It saturation for extreme values, making it suitable for probailities outputs.\n"
      ],
      "metadata": {
        "id": "MqooDuDChP4C"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S6fqh2szhPU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. What is the cost function of Logistic Regression."
      ],
      "metadata": {
        "id": "tlnXPuQCjAGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Logistic Regression, we use cross_entropy loss/cost function:\n",
        "\n",
        "```\n",
        "J(theta) = y_i*log(f(x_i)) + (1 - y_i)*log(1-f(x_i))\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "pGcF1vpejCQg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qjcqguuDjByp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. What is Regularization in Logistic Regression? Why is it needed."
      ],
      "metadata": {
        "id": "BAl_gJfFjet4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regularization is penalising the model, to avoid overfitting on the training data and generalising it for test data.\n",
        "\n",
        "For situation with complicated seperation in different classes, we do not prefer the model to remember the  the training data points distribution (rather the meaningful pattern), it will cause poor performance on test data and fail to generalise.\n",
        "For this purpose, regularization is needed.\n"
      ],
      "metadata": {
        "id": "1XTAjNjAjiSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yCsUPnukjA64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7. Explain the difference between Lasso, Ridge, and Elastic Net regression."
      ],
      "metadata": {
        "id": "mWWG3b_MlAOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1 Ridge(L2) Regression reduces overfitting by penalizeing the model.\n",
        "\n",
        "1.2 Lasso(L1) Regression primarily focuses on reducing weightage of poorly correlated features from model.\n",
        "\n",
        "1.3 Elastic-Net is linear combination of both of them.\n",
        "\n",
        "\n",
        "2.1 Ridge Regression decreases weight of poorly correlated variable but never makes them zero and is useful to counter overfitting.\n",
        "\n",
        "2.2 Lasso Regression shrinks them exactly zero and is useful to remove irrelevant features.\n",
        "\n",
        "2.3 Elastic-Net is usefil when there are highly correlated variables."
      ],
      "metadata": {
        "id": "Wq3gX6X4lCk1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D7a67zw6lBvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7. When should we use Elastic Net instead of Lasso or Ridge."
      ],
      "metadata": {
        "id": "aLhTbZOFmX-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we have highly correlated multiple feautres.\n",
        "Lasso may struggle with shrinking weightage feature selection between useful and irrelevant features."
      ],
      "metadata": {
        "id": "INstIpbtmccd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ls22Zx3omaKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###8. What is the impact of the regularization parameter (Î») in Logistic Regression."
      ],
      "metadata": {
        "id": "OaL1GV-kn17s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lambda is the scaling parameter in L1,L2 and elastic-net regulatization.\n",
        "\n",
        "Greater the value of lambda, more will be regularization on the model.\n",
        "\n",
        "\n",
        "Lambda moves inversly to the weight parameter. More the value of lambda, more the weights will shrink."
      ],
      "metadata": {
        "id": "Pl6esljsn6FN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QE8l26lfn3Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###9. What are the key assumptions of Logistic Regression."
      ],
      "metadata": {
        "id": "pAnCKKBVoll6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. All the classes are equally balanced in dataset.\n",
        "\n",
        "2. Data is linear seperable.\n",
        "\n",
        "3. Log of the target variable have linear relationship with input variable.\n",
        "\n",
        "4. No multicollinearity.\n",
        "\n",
        "5. Independence of observations."
      ],
      "metadata": {
        "id": "Q6t1zqrsonvY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3CEzkQvFonMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###10. What are some alternatives to Logistic Regression for classification tasks."
      ],
      "metadata": {
        "id": "R4me4KLBqXZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Support Vector Machine\n",
        "\n",
        "> Decision Trees\n",
        "\n",
        "> Naive Bayse\n",
        "\n",
        "> Random Forest\n",
        "\n",
        "> Gradient Boost classification\n",
        "\n",
        ">XGB classification"
      ],
      "metadata": {
        "id": "rDOLhtmxqZNi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uxCBVc47qYla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###11. What are Classification Evaluation Metrics."
      ],
      "metadata": {
        "id": "AiKT6LtJquPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy_score,\n",
        "Precision_score,\n",
        "Classification_matric,\n",
        "ROC-AUC curve,\n",
        "Recall_score"
      ],
      "metadata": {
        "id": "jrRTpabTqwOi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8-AzRvSyqvPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###12. How does class imbalance affect Logistic Regression."
      ],
      "metadata": {
        "id": "Jaicblykq_NC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If left unattended, the model can miss the key patterns in the imbalanced class.\n",
        "\n",
        "Model can overlearn the parameter of one class and overfit.\n",
        "\n",
        "The decision boundary, ultimately, will be skewed toward the majority and will be less sensitive to the minority class."
      ],
      "metadata": {
        "id": "DGrvcKS6rA0J"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z-IOSoTVrASV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###13. What is Hyperparameter Tuning in Logistic Regression."
      ],
      "metadata": {
        "id": "vs3jQWtTr7jx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The process of finding the hyperparameters of the model such that model performs best on the training and test model is called hyperparameter tuning.\n",
        "\n",
        "For logistic Regression, we have `penalty`, `C` , `class_weight`, `solver`, `max_iters` as some of hyperparameters.\n",
        "\n",
        "Tuning these parameters will avoid over/underfitting and custom the model to fit on given dataset."
      ],
      "metadata": {
        "id": "aC2r96hxr9k2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y8qXN9Vhr9GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###14. What are different solvers in Logistic Regression? Which one should be used."
      ],
      "metadata": {
        "id": "FogC9ozrs6-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Logistic Regression, there are 4 major solvers:\n",
        "`lbfgs`, `liblinear`, `newton-cg`, `newton-cholesky`.\n",
        "\n",
        "Out of these, `liblinear` is for small datasets and `lbfgs` is good choice for binary classification.\n",
        "``newton-cholesky`` is used when n_samples>>n_features * n_classes.\n",
        "\n"
      ],
      "metadata": {
        "id": "6auc6v43s8sX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n0venzh7s8HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###15. How is Logistic Regression extended for multiclass classification."
      ],
      "metadata": {
        "id": "npWZVIzVupPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can change the function for Logistic Regression from Sigmoid to softmax.\n",
        "\n",
        "It will calculate proabability of data point belonging to each class and then return the class with highest probability/score."
      ],
      "metadata": {
        "id": "VCa2vuH6uq4d"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N4uvd-XluqXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###16. What are the advantages and disadvantages of Logistic Regression."
      ],
      "metadata": {
        "id": "KrEQc-ltvYzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advantages:\n",
        "1. Computationally cheap.\n",
        "\n",
        "2. Function is differentiable and optimizable.\n",
        "\n",
        "3. Outputs interpretable probailities.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "1. Fails for more complex decision boundaries.\n",
        "\n",
        "2. Difficult to scale in higher feautre planes.\n",
        "\n",
        "3. Assumes linearity.\n",
        "\n",
        "4. Prone to overfitting is n_features>>n_data_points.\n",
        "\n",
        "5. Low sensitive to outliers."
      ],
      "metadata": {
        "id": "PCDaJObAvcjb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "69JjIZWjvcCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###17. What are some use cases of Logistic Regression."
      ],
      "metadata": {
        "id": "gCGiJWofwofS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To classify spam/ham.\n",
        "\n",
        "To classify fraud/not fraud from transaction dataset.\n",
        "\n",
        "To classify spam/not spam email.\n",
        "\n",
        "To classify real/fake news (post tokenization of text).\n",
        "\n"
      ],
      "metadata": {
        "id": "zem5gvozwqZr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QvstpgUavaWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###18. What is the difference between Softmax Regression and Logistic Regression."
      ],
      "metadata": {
        "id": "K6Wu33ufxExO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression uses sigmoid as function.\n",
        "Softmax Regression modifies it to softmax function for decision boundary.\n",
        "\n",
        "Logistic regression in inherintly binary classification algorithm.\n",
        "Softmax is multiclass classification algorithm.\n",
        "\n",
        "For softmax, `f(x)=x ; x>0` and `f(x) = 0 ; x<=0` .\n",
        "\n",
        "for logistic:\n",
        "\n",
        "`sigma(z) = 1/(1+exp(-z))`\n",
        "\n",
        "everywhere."
      ],
      "metadata": {
        "id": "0SC77g4vxG4W"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0-XeGmXGxGYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "`# This is formatted as code`\n",
        "```\n",
        "\n",
        "###19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification."
      ],
      "metadata": {
        "id": "FyjSj1EYx-55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OvR: -\n",
        "\n",
        "\n",
        "*   When datasset has imbalanced calsses, since its easier to tune each class independently.\n",
        "*   When we want more control over class specific thresolds.\n",
        "*   When we are using non- probabilistic models like Logistic Regression or Decision Trees.\n",
        "\n",
        "Softmax: -\n",
        "\n",
        "\n",
        "*   Its mostly used when we are working with neural networks.\n",
        "*   When we want end-to-end training with gradients.\n",
        "*   Classes are mutually exclusive.\n",
        "*  When number of classes training are small.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8kUZJfvK2cMI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bL-p8409yAgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###20. How do we interpret coefficients in Logistic Regression?"
      ],
      "metadata": {
        "id": "O25Q1p_M3tOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Logistic regression, we deal with log-odds coefficents $\\beta$ rather than simple weight coefficents $\\alpha$.\n",
        "\n",
        "$\\beta$ = log(p/(1-p))\n",
        "\n",
        "$\\beta_{i}$>0 --> increasing that feature $x_{i}$ will increase the log-odds and hence the probability of positive class.\n",
        "\n",
        "Similaraly, $\\beta_{i}$<0 --> implies that increasing $x_{i}$ will decrease the log-odds i.e. probability of positive class."
      ],
      "metadata": {
        "id": "99DhCK1u3zen"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NTtDV6t_3y4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practical Questions"
      ],
      "metadata": {
        "id": "QYxMaTiA5DBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy."
      ],
      "metadata": {
        "id": "g8bj8N0F5gkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Loading data\n",
        "data = load_iris()\n",
        "X = data.data       # Features\n",
        "y = data.target     # Target\n",
        "\n",
        "#train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#model training\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#calculating and printing accuracy metrics\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Logistic Regression Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeuzsBew5E_t",
        "outputId": "a539c4c1-4f83-4a60-decd-754ffcc4fe5f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy."
      ],
      "metadata": {
        "id": "EaZPpvgM58D1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Step 6: Print accuracy\n",
        "print(f\"Model Accuracy with L1 Regularization: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7iws7n354GH",
        "outputId": "2f3f9bcc-51a7-43fd-99b9-d015600e9cb4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L1 Regularization: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients."
      ],
      "metadata": {
        "id": "F4m_jVZRBfvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(penalty='l2')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#Evaluating the model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# accuracy and coefficients\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "print(\"Model Coefficients:\")\n",
        "for i, class_coef in enumerate(model.coef_):\n",
        "    print(f\"Class {i}: {class_coef}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h55o1Pb_6KxR",
        "outputId": "7df7f83b-c647-4dd1-f8c6-251832cc225d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n",
            "Model Coefficients:\n",
            "Class 0: [-0.39345607  0.96251768 -2.37512436 -0.99874594]\n",
            "Class 1: [ 0.50843279 -0.25482714 -0.21301129 -0.77574766]\n",
            "Class 2: [-0.11497673 -0.70769055  2.58813565  1.7744936 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')."
      ],
      "metadata": {
        "id": "jzYiaV5ACXX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(\n",
        "    penalty='elasticnet',\n",
        "    solver='saga',\n",
        "    l1_ratio=0.5\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluating the model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Printing accuracy\n",
        "print(f\"Model Accuracy with Elastic Net: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sOhuR53Bxkr",
        "outputId": "e6f3eb4a-ac05-42b1-ec6d-51bebed31de1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with Elastic Net: 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'."
      ],
      "metadata": {
        "id": "WtkoOMGxC5FA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Output results\n",
        "print(f\"Multiclass Logistic Regression (OvR) Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0quDugPDCkQP",
        "outputId": "6ba112a5-172f-4fdd-8c28-81e0897f454a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Logistic Regression (OvR) Accuracy: 0.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy."
      ],
      "metadata": {
        "id": "IRPJfKDEEpkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# Grid search\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Evaluating on test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Output\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(f\"Test Accuracy with Best Model: {test_accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CApEUpaDmHD",
        "outputId": "40641bc1-06ed-4fc1-a801-a6e145950caf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 1, 'penalty': 'l2'}\n",
            "Test Accuracy with Best Model: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy."
      ],
      "metadata": {
        "id": "rWqRQQPMFaGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Define model\n",
        "model = LogisticRegression(solver='liblinear', multi_class='ovr', max_iter=1000)\n",
        "\n",
        "# Setting up Stratified K-Fold Cross-Validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Evaluate model using cross_val_score\n",
        "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "# Print results\n",
        "print(\"Accuracy for each fold:\", scores)\n",
        "print(f\"Average Accuracy: {np.mean(scores):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doYiu94SFEok",
        "outputId": "a6b23afa-97e8-48d0-97ee-2bf691e3b701"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for each fold: [0.94444444 0.97222222 0.94444444 0.97142857 1.        ]\n",
            "Average Accuracy: 0.9665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy."
      ],
      "metadata": {
        "id": "82U0hNvZFy0K"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LL4BU8OjhoCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "# View first few rows\n",
        "print(df.head())\n",
        "\n",
        "df.to_csv(\"breast_cancer_data.csv\", index=False)\n",
        "\n",
        "df = pd.read_csv('/content/sample_data/breast_cancer_data.csv')\n",
        "\n",
        "X = df.drop(columns = ['target'])\n",
        "y = df[['target']]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Output results\n",
        "print(f\"Multiclass Logistic Regression (OvR) Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0IBWb8UIFZo",
        "outputId": "2d3eb42c-154c-4c2b-c705-aaa9aca85b9b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0        17.99         10.38          122.80     1001.0          0.11840   \n",
            "1        20.57         17.77          132.90     1326.0          0.08474   \n",
            "2        19.69         21.25          130.00     1203.0          0.10960   \n",
            "3        11.42         20.38           77.58      386.1          0.14250   \n",
            "4        20.29         14.34          135.10     1297.0          0.10030   \n",
            "\n",
            "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0           0.27760          0.3001              0.14710         0.2419   \n",
            "1           0.07864          0.0869              0.07017         0.1812   \n",
            "2           0.15990          0.1974              0.12790         0.2069   \n",
            "3           0.28390          0.2414              0.10520         0.2597   \n",
            "4           0.13280          0.1980              0.10430         0.1809   \n",
            "\n",
            "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
            "0                 0.07871  ...          17.33           184.60      2019.0   \n",
            "1                 0.05667  ...          23.41           158.80      1956.0   \n",
            "2                 0.05999  ...          25.53           152.50      1709.0   \n",
            "3                 0.09744  ...          26.50            98.87       567.7   \n",
            "4                 0.05883  ...          16.67           152.20      1575.0   \n",
            "\n",
            "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
            "0            0.1622             0.6656           0.7119                0.2654   \n",
            "1            0.1238             0.1866           0.2416                0.1860   \n",
            "2            0.1444             0.4245           0.4504                0.2430   \n",
            "3            0.2098             0.8663           0.6869                0.2575   \n",
            "4            0.1374             0.2050           0.4000                0.1625   \n",
            "\n",
            "   worst symmetry  worst fractal dimension  target  \n",
            "0          0.4601                  0.11890       0  \n",
            "1          0.2750                  0.08902       0  \n",
            "2          0.3613                  0.08758       0  \n",
            "3          0.6638                  0.17300       0  \n",
            "4          0.2364                  0.07678       0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "Multiclass Logistic Regression (OvR) Accuracy: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy."
      ],
      "metadata": {
        "id": "sMIsF2LSJpBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "model = LogisticRegression()\n",
        "\n",
        "param_dist = {\n",
        "    'C': [0.001, 100],  # Search over a wide range of C values\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV setup\n",
        "random_search = RandomizedSearchCV(\n",
        "    model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,             # Number of random combinations to try\n",
        "    cv=5,                  # 5-fold cross-validation\n",
        "    scoring='accuracy',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit search\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model and test accuracy\n",
        "best_model = random_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Output\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2yrLYThJLlz",
        "outputId": "dd64acdc-5fd8-4595-b1ea-3f26dfcad7b4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 100}\n",
            "Test Accuracy: 0.9825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy."
      ],
      "metadata": {
        "id": "5n_kTGh8KMim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "logreg = LogisticRegression(solver='liblinear', max_iter=1000)\n",
        "\n",
        "# Using with OneVsOneClassifier\n",
        "ovo_model = OneVsOneClassifier(logreg)\n",
        "\n",
        "# Train the model\n",
        "ovo_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = ovo_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Output results\n",
        "print(f\"One-vs-One Logistic Regression Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RHV-Na5KAwd",
        "outputId": "52f9624b-2a8f-493e-f43f-09aa904510c4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-vs-One Logistic Regression Accuracy: 0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification."
      ],
      "metadata": {
        "id": "js_Ido85LC0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Output results\n",
        "print(f\"Multiclass Logistic Regression (OvR) Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix - One-vs-One Logistic Regression')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "xyhp-iEPKjhP",
        "outputId": "db346f66-2817-4c29-8b08-e878c588035c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Logistic Regression (OvR) Accuracy: 0.96\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score."
      ],
      "metadata": {
        "id": "af218aqpMcmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score, precision_score,f1_score\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "recall = recall_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "f1_score = f1_score(y_test, y_pred)\n",
        "\n",
        "# Output results\n",
        "print(f\"Multiclass Logistic Regression Percision: {precision:.2f}\")\n",
        "print(f\"Multiclass Logistic Regression recall: {recall:.2f}\")\n",
        "print(f\"Multiclass Logistic Regression f1_score: {f1_score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEk4QuDmL6TC",
        "outputId": "53a4791e-f7af-4cd4-f24b-14b3bc1bc7b2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Logistic Regression Percision: 0.95\n",
            "Multiclass Logistic Regression recall: 0.99\n",
            "Multiclass Logistic Regression f1_score: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance."
      ],
      "metadata": {
        "id": "yqvP8fDoNYUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import classification_report\n",
        "X,y = make_classification(n_samples = 1000,n_features = 5,n_informative=2,n_redundant=3,n_classes=2,weights = [0.80,0.20],random_state = 42)\n",
        "\n",
        "feature_names = [f'feature_{i}' for i in range(X.shape[1])]\n",
        "df = pd.DataFrame(X, columns=feature_names)\n",
        "df['target'] = y\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop('target', axis=1), df['target'], test_size=0.2, stratify=df['target'], random_state=42)\n",
        "\n",
        "# Training Logistic Regression without class weights\n",
        "model_plain = LogisticRegression(solver='liblinear')\n",
        "model_plain.fit(X_train, y_train)\n",
        "y_pred_plain = model_plain.predict(X_test)\n",
        "\n",
        "# Training Logistic Regression with class weights\n",
        "model_weighted = LogisticRegression(solver='liblinear', class_weight='balanced')\n",
        "model_weighted.fit(X_train, y_train)\n",
        "y_pred_weighted = model_weighted.predict(X_test)\n",
        "\n",
        "# Evaluating both models\n",
        "print(\"\\n--- Without Class Weights ---\")\n",
        "print(confusion_matrix(y_test, y_pred_plain))\n",
        "print(classification_report(y_test, y_pred_plain))\n",
        "\n",
        "print(\"\\n--- With Class Weights ---\")\n",
        "print(confusion_matrix(y_test, y_pred_weighted))\n",
        "print(classification_report(y_test, y_pred_weighted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIc2EeAfmIjD",
        "outputId": "acb0e881-e5b2-4537-dd61-bac793ccfb43"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Without Class Weights ---\n",
            "[[152   7]\n",
            " [ 11  30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.94       159\n",
            "           1       0.81      0.73      0.77        41\n",
            "\n",
            "    accuracy                           0.91       200\n",
            "   macro avg       0.87      0.84      0.86       200\n",
            "weighted avg       0.91      0.91      0.91       200\n",
            "\n",
            "\n",
            "--- With Class Weights ---\n",
            "[[137  22]\n",
            " [  4  37]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.86      0.91       159\n",
            "           1       0.63      0.90      0.74        41\n",
            "\n",
            "    accuracy                           0.87       200\n",
            "   macro avg       0.80      0.88      0.83       200\n",
            "weighted avg       0.90      0.87      0.88       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance."
      ],
      "metadata": {
        "id": "hmrQpo9PnWYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 1. Load Titanic dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# Selecting relevant columns\n",
        "df = df[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']]\n",
        "\n",
        "# Handling missing values\n",
        "df['age'].fillna(df['age'].median(), inplace=True)\n",
        "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# Encoding categorical features\n",
        "le_sex = LabelEncoder()\n",
        "le_embarked = LabelEncoder()\n",
        "df['sex'] = le_sex.fit_transform(df['sex'])\n",
        "df['embarked'] = le_embarked.fit_transform(df['embarked'])\n",
        "\n",
        "# 5. Split into features and target and into train-test pairs\n",
        "X = df.drop('survived', axis=1)\n",
        "y = df['survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the test set and evaluating\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQqonQFPn2o5",
        "outputId": "e702edc8-0913-4dd4-a49a-05da4d2a0185"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8100558659217877\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84       105\n",
            "           1       0.79      0.74      0.76        74\n",
            "\n",
            "    accuracy                           0.81       179\n",
            "   macro avg       0.81      0.80      0.80       179\n",
            "weighted avg       0.81      0.81      0.81       179\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#We will work with Titanic dataset in following questions, unless otherwise stated.#"
      ],
      "metadata": {
        "id": "v8KLgDXOmzSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling."
      ],
      "metadata": {
        "id": "FqcWlyl5ihle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Encode categorical features\n",
        "le_sex = LabelEncoder()\n",
        "le_embarked = LabelEncoder()\n",
        "df['sex'] = le_sex.fit_transform(df['sex'])\n",
        "df['embarked'] = le_embarked.fit_transform(df['embarked'])\n",
        "\n",
        "# Define features and target and train-test split pair\n",
        "X = df.drop('survived', axis=1)\n",
        "y = df['survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model WITHOUT scaling\n",
        "model_plain = LogisticRegression(max_iter=1000)\n",
        "model_plain.fit(X_train, y_train)\n",
        "y_pred_plain = model_plain.predict(X_test)\n",
        "\n",
        "print(\"Without Scaling\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_plain))\n",
        "print(classification_report(y_test, y_pred_plain))\n",
        "\n",
        "# Model WITH StandardScaler (Z-score scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "\n",
        "print(\"With StandardScaler\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_scaled))\n",
        "print(classification_report(y_test, y_pred_scaled))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEIhpTBqn6oY",
        "outputId": "380f3461-084a-42ae-9dec-3f1e10a269b6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without Scaling\n",
            "Accuracy: 0.8100558659217877\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84       105\n",
            "           1       0.79      0.74      0.76        74\n",
            "\n",
            "    accuracy                           0.81       179\n",
            "   macro avg       0.81      0.80      0.80       179\n",
            "weighted avg       0.81      0.81      0.81       179\n",
            "\n",
            "With StandardScaler\n",
            "Accuracy: 0.8044692737430168\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84       105\n",
            "           1       0.78      0.73      0.76        74\n",
            "\n",
            "    accuracy                           0.80       179\n",
            "   macro avg       0.80      0.79      0.80       179\n",
            "weighted avg       0.80      0.80      0.80       179\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score."
      ],
      "metadata": {
        "id": "RGx0L66Vjg3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predicting probabilities for ROC curve\n",
        "y_probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_probs)\n",
        "print(\"ROC-AUC Score:\", roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtLWTF0-i9uD",
        "outputId": "8ac2147b-c878-4dee-d9ed-ec58dadfe85c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.8823680823680824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####17. Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy."
      ],
      "metadata": {
        "id": "Dg9ZGxLZj9kX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training Logistic Regression model\n",
        "model = LogisticRegression(C=0.5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the test set and evaluating\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tnT-JBKjt1X",
        "outputId": "21ca635b-f6fb-429a-d5f0-b842c237e94c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8100558659217877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####18. Write a Python program to train Logistic Regression and identify important features based on model coefficients."
      ],
      "metadata": {
        "id": "h-OCEU8WkdEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(C=0.5, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "coefficients = model.coef_[0]\n",
        "feature_names = X.columns\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': coefficients,\n",
        "    'Abs_Coefficient': np.abs(coefficients)\n",
        "}).sort_values(by='Abs_Coefficient', ascending=False)\n",
        "\n",
        "print(\"\\nImportant Features (based on absolute coefficient values):\")\n",
        "print(feature_importance[['Feature', 'Coefficient']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JcYYRI_kZ1v",
        "outputId": "b97d80cc-f0bd-4c0f-c8d9-f2c7c17f157c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8100558659217877\n",
            "\n",
            "Important Features (based on absolute coefficient values):\n",
            "    Feature  Coefficient\n",
            "1       sex    -2.482772\n",
            "0    pclass    -0.898465\n",
            "3     sibsp    -0.285053\n",
            "6  embarked    -0.215236\n",
            "4     parch    -0.097896\n",
            "2       age    -0.029755\n",
            "5      fare     0.002690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####19. Write a Python program to train Logistic Regression and evaluate its performance using Cohenâs Kappa Score."
      ],
      "metadata": {
        "id": "9rWXveOflCab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "print(\"Cohen's Kappa Score:\", kappa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQgLzjxYk2BX",
        "outputId": "181029ef-35aa-43f3-aad6-e62caa144451"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8100558659217877\n",
            "Cohen's Kappa Score: 0.605215360664245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification."
      ],
      "metadata": {
        "id": "pJ_Ggcy5lZSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_scores = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "avg_precision = average_precision_score(y_test, y_scores)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, label=f'AP = {avg_precision:.2f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "XK1eHsUIlN_G",
        "outputId": "bb74a36c-ce68-48c2-fd26-a7e6e00ecbb7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy."
      ],
      "metadata": {
        "id": "WFxsbW8Wlu7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "\n",
        "results = {}\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver, max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    results[solver] = acc\n",
        "\n",
        "# Print results\n",
        "print(\"Accuracy by solver:\")\n",
        "for solver, acc in results.items():\n",
        "    print(f\"{solver}: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaSM1PpalrNS",
        "outputId": "d87d799e-166b-44f1-ca55-8b0556442131"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy by solver:\n",
            "liblinear: 0.7821\n",
            "saga: 0.7095\n",
            "lbfgs: 0.8101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####22. Write a Python program to train Logistic Regression and evaluate its performance using Matthews Correlation Coefficient (MCC)."
      ],
      "metadata": {
        "id": "ln-BYD_umBY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "\n",
        "print(\"Matthews Correlation Coefficient (MCC):\", mcc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z76c5vS6l9Iv",
        "outputId": "846ffb38-efa3-4476-a6fc-335a55dff9bc"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient (MCC): 0.6058691922784846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####23. Write a Python program to train Logistic Regression on both raw and standardized data. Compare their accuracy to see the impact of feature scaling."
      ],
      "metadata": {
        "id": "lrygXt_YmTh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = sns.load_dataset('titanic')\n",
        "df = df[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']]\n",
        "df['age'].fillna(df['age'].median(), inplace=True)\n",
        "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
        "df['sex'] = LabelEncoder().fit_transform(df['sex'])\n",
        "df['embarked'] = LabelEncoder().fit_transform(df['embarked'])\n",
        "\n",
        "X = df.drop('survived', axis=1)\n",
        "y = df['survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model_raw = LogisticRegression(max_iter=1000)\n",
        "model_raw.fit(X_train, y_train)\n",
        "y_pred_raw = model_raw.predict(X_test)\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(\"Accuracy on raw data: {:.4f}\".format(accuracy_raw))\n",
        "print(\"Accuracy on standardized data: {:.4f}\".format(accuracy_scaled))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foE_ti6YmOZS",
        "outputId": "e0b92b38-ff65-4a53-9aa5-daeaf90327a2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on raw data: 0.8101\n",
            "Accuracy on standardized data: 0.8045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####24. Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using cross-validation."
      ],
      "metadata": {
        "id": "EcqORKbHnBBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "best_C = grid_search.best_params_['C']\n",
        "\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Best C: {best_C}\")\n",
        "print(f\"Test set accuracy with best C: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBsqUlQemnBH",
        "outputId": "498ce8e7-67d2-4738-f054-fe4c689a8a96"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best C: 0.01\n",
            "Test set accuracy with best C: 0.7877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to make predictions."
      ],
      "metadata": {
        "id": "q3b9tyJKnRyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "joblib.dump(model, 'logistic_model.joblib')\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "\n",
        "loaded_model = joblib.load('logistic_model.joblib')\n",
        "loaded_scaler = joblib.load('scaler.joblib')\n",
        "\n",
        "X_test_scaled_loaded = loaded_scaler.transform(X_test)\n",
        "y_pred = loaded_model.predict(X_test_scaled_loaded)\n",
        "\n",
        "print(\"Accuracy of loaded model:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcCtj4oAnN54",
        "outputId": "7d2480b4-f8f1-4a9b-c4a6-fbb6b68c2fd9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of loaded model: 0.8044692737430168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vm-tNFrQnhlC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}